<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="theme-color" content="#0990d0">
    <!-- Google Search Console -->
    <meta name="google-site-verification" content="AvoEr3mUJFF2H_mPWWgShfmjBVP3ywRpyx9hxeeq2d4">
    <title>Scrapy を使ってクローリング・スクレイピングしてみる - Neo's World</title>
    <link rel="icon" href="/favicon.ico">
    <link rel="stylesheet" href="/styles.css">
    <link rel="canonical" href="https://neos21.net/blog/2020/01/31-03.html">
    <link rel="search" type="application/opensearchdescription+xml" title="neos21.net" href="/opensearch.xml">
    <link rel="alternate" type="application/atom+xml" href="/feeds.xml">
    <link rel="author" href="http://www.hatena.ne.jp/neos21/">
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YMHFLZP1M1"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date());gtag('config','G-YMHFLZP1M1');gtag('config','UA-106501-1');</script>
    <!-- Google AdSense -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6475907504235292" crossorigin="anonymous"></script>
  </head>
  <body>
    <div id="container">
      <header id="header">
        <div id="header-brand">
          <div id="header-brand-contents">
            <div id="site-title"><a href="/index.html">Neo's World</a></div>
            <nav id="header-links">
              <ul>
                <li id="header-link-about"><a href="/about/index.html" title="About"><span>About</span></a></li>
                <li id="header-link-search"><a href="/about/search.html" title="Search"><span>Search</span></a></li>
                <li id="header-link-feeds"><a href="/feeds.xml" title="Feeds"><span>Feeds</span></a></li>
                <li id="header-link-to-bottom"><a href="#footer" title="To Bottom"><span>▼ To Bottom</span></a></li>
              </ul>
            </nav>
          </div>
        </div>
        <nav id="global-nav">
          <ul>
            <li><a href="/blog/index.html">Blog</a></li>
            <li><a href="/tech/index.html">Tech</a></li>
            <li><a href="/music/index.html">Music</a></li>
            <li><a href="/games/index.html">Games</a></li>
            <li><a href="/gallery/index.html">Gallery</a></li>
            <li><a href="/etc/index.html">Etc.</a></li>
          </ul>
        </nav>
        <nav id="path">
          <ul>
            <li><a href="/index.html">Neo's World</a></li>
            <li><a href="/blog/index.html">Blog</a></li>
            <li><a href="/blog/2020/index.html">2020年</a></li>
            <li><a href="/blog/2020/01/index.html">01月</a></li>
          </ul>
        </nav>
      </header>
      <main id="main">
        <div id="header-date"><time>2020-01-31</time></div>
        <h1 id="page-title">Scrapy を使ってクローリング・スクレイピングしてみる</h1>

<p>Python 製のスクレイピング・ライブラリ<strong>「Scrapy」</strong>を使ってみる。</p>
<h2 id="目次"><a class="header-link" href="#目次"><span class="header-link-mark"></span></a>目次</h2>
<ul>
  <li><a href="#scrapy-%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">Scrapy プロジェクトを作成する</a></li>
  <li><a href="#%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B">クローリングの設定を変更する</a></li>
  <li><a href="#%E3%82%B9%E3%83%91%E3%82%A4%E3%83%80%E3%83%BC%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">スパイダーを作成する</a></li>
  <li><a href="#item-%E3%82%92%E5%AE%9A%E7%BE%A9%E3%81%99%E3%82%8B">Item を定義する</a></li>
  <li><a href="#%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0%E5%87%A6%E7%90%86%E3%82%92%E5%AE%9F%E8%A3%85%E3%81%99%E3%82%8B">スクレイピング処理を実装する</a></li>
  <li><a href="#%E4%BD%9C%E6%88%90%E3%81%97%E3%81%9F-spider-%E3%82%92%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B">作成した Spider を実行する</a></li>
  <li><a href="#%E3%83%9A%E3%83%BC%E3%82%B8%E9%81%B7%E7%A7%BB%E3%82%92%E4%BC%B4%E3%81%86%E8%A4%87%E6%95%B0-item-%E3%82%92%E6%89%B1%E3%81%86%E5%A0%B4%E5%90%88">ページ遷移を伴う・複数 Item を扱う場合</a>
    <ul>
      <li><a href="#%E9%A1%8C%E6%9D%90">題材</a></li>
      <li><a href="#item-%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">Item を作成する</a></li>
      <li><a href="#spider-%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">Spider を作成する</a></li>
    </ul>
  </li>
  <li><a href="#%E5%85%A5%E3%82%8C%E5%AD%90%E3%81%AE-item-%E3%82%92%E5%87%BA%E5%8A%9B%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E3%82%89">入れ子の Item を出力しようとしたら…</a></li>
  <li><a href="#%E4%BB%A5%E4%B8%8A">以上</a></li>
</ul>
<h2 id="scrapy-プロジェクトを作成する"><a class="header-link" href="#scrapy-プロジェクトを作成する"><span class="header-link-mark"></span></a>Scrapy プロジェクトを作成する</h2>
<p>作業ディレクトリを作り、<em>pipenv</em> を使って環境構築し、Scrapy をインストールしていく。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># Pipfile を初期生成する</span>
$ pipenv --python <span class="token number">3.7</span>
<span class="token comment"># Pipfile、Pipfile.lock、.venv/ が生成される</span>

<span class="token comment"># Scrapy をインストールする</span>
$ pipenv <span class="token function">install</span> scrapy

<span class="token comment"># 「pipenv run scrapy」と打たずに「scrapy」とコマンドが実行できるようシェルを読み込む</span>
$ pipenv shell

<span class="token comment"># Scrapy プロジェクトを作成する</span>
$ scrapy startproject my_scrapy <span class="token builtin class-name">.</span>
<span class="token comment"># scrapy.cfg ファイル、my_scrapy/ ディレクトリが生成される</span>
</code></pre>
<p><code>scrapy startproject 【プロジェクト名】 【作成するパス】</code> というコマンドで、Scrapy 用のプロジェクトを作る。カレントディレクトリに作るようにすると、以下のようなファイルが自動生成されるはずだ。</p>
<pre><code>【作業ディレクトリ】/
├ scrapy.cfg
└ 【プロジェクト名】/ … 上の例では「my_scrapy/」
   ├ __init__.py
   ├ items.py
   ├ middlewares.py
   ├ pipelines.py
   ├ settings.py
   └ spiders/
      └ __init__.py
</code></pre>
<p>それぞれのファイルの意味は順を追って理解していくとする。</p>
<h2 id="クローリングの設定を変更する"><a class="header-link" href="#クローリングの設定を変更する"><span class="header-link-mark"></span></a>クローリングの設定を変更する</h2>
<p>まずは <code>settings.py</code> を開き、クローリングの設定を変更していく。やっておきたい設定は以下のとおり。</p>
<ul>
  <li><code>DOWNLOAD_DELAY</code> を設定し、クロール先に連続したアクセスをしないよう秒間を開ける
    <ul>
      <li>ex. <code>DOWNLOAD_DELAY = 3</code> (3秒間隔を開ける)</li>
    </ul>
  </li>
  <li><code>HTTPCACHE_</code> から始まる設定を有効にしておく。コレにより、作業ディレクトリ直下に <code>.scrapy/</code> というディレクトリができ、その中にキャッシュが保存される
    <ul>
      <li>キャッシュによって正常にクロールできなくなる場合もあるので、その時は <code>.scrapy/</code> ディレクトリごと削除してやり直せば OK</li>
      <li>参考：<a href="https://qiita.com/Chanmoro/items/f4df85eb73b18d902739">10分で理解する Scrapy - Qiita</a></li>
    </ul>
  </li>
  <li><code>USER_AGENT</code> を設定しておく
    <ul>
      <li>ex. <code>USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'</code> (MacOS・Chrome を使用しているテイ)</li>
      <li>参考：<a href="https://note.nkmk.me/python-scrapy-tutorial/">Python, Scrapyの使い方（Webクローリング、スクレイピング） | note.nkmk.me</a></li>
    </ul>
  </li>
  <li>スクレイピング結果を JSON 出力する際、日本語文字が Unicode エンコーディングになるのを防ぐため、以下の設定を追加する
    <ul>
      <li><code>FEED_EXPORT_ENCODING = 'utf-8'</code></li>
      <li>参考：<a href="https://qiita.com/shiozaki/items/689713b4cfb869e7f54c">scrapyのJSON出力を日本語にする方法 - Qiita</a></li>
    </ul>
  </li>
</ul>
<h2 id="スパイダーを作成する"><a class="header-link" href="#スパイダーを作成する"><span class="header-link-mark"></span></a>スパイダーを作成する</h2>
<p>スクレイピング関連の一般的な用語整理。</p>
<ul>
  <li>Spider スパイダー : クロール先 URL を特定する</li>
  <li>Crawler クローラー : スパイダーが収集した URL にアクセスして、レスポンス (HTML や REST API の JSON など) を取得する</li>
  <li>Scraper スクレイパー : クローラーが取得したレスポンスから特定のデータを抽出・加工する</li>
</ul>
<p>Scrapy では、これらの処理をまるっと「Spider」と呼ぶクラスが担う形になる。Scrapy でいうところの「スパイダー」を作ってみよう。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># 作成した Scrapy プロジェクトに移動する</span>
$ <span class="token builtin class-name">cd</span> my_scrapy/

<span class="token comment"># 以下のコマンドで Spider を作成する</span>
$ scrapy genspider my_example example.com
</code></pre>
<p><code>scrapy genspider 【Spider 名】 【取得するサイトのドメイン】</code> と記す。ドメイン部分は、<code>https://</code> などのプロトコルを付けず、ドメイン配下を付けてはならない。</p>
<ul>
  <li><strong>以下は指定する文字列として悪い例</strong>
    <ul>
      <li><code>https://example.com</code></li>
      <li><code>https://example.com/index.html</code></li>
      <li><code>example.com/index.html</code></li>
    </ul>
  </li>
  <li><em>次のように書くこと</em>
    <ul>
      <li><code>example.com</code></li>
    </ul>
  </li>
</ul>
<p>1つの Spider につき、1つのサイトのドメインを扱う形になる。</p>
<p>このようにコマンドを実行すると、<code>./【Scrapy プロジェクト名】/spiders/【指定した Spider 名】.py</code> というファイルができているはずだ。</p>
<ul>
  <li><code>./my_scrapy/spiders/my_example.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MyExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
  name <span class="token operator">=</span> <span class="token string">'my_example'</span>
  allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'example.com'</span><span class="token punctuation">]</span>
  start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://example.com/'</span><span class="token punctuation">]</span>
  
  <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">pass</span>
</code></pre>
<p>コレで Spider の雛形が出来たことになる。</p>
<p><code>start_urls</code> 部分でクロール対象の URL を指定する。一般的な用語でいう「スパイダー」の役割は、この <code>start_urls</code> に URL を列挙することで担う。クロール対象 URL 部分を動的に処理して収集していくこともできるが、今回は割愛。予めクロールしたい URL を配列で列挙しておくこととする。</p>
<p>「クロール」処理は、Scrapy が自動的に行い、レスポンスを <code>parse()</code> 関数に渡してくれる。開発者は <code>parse()</code> 関数内で「スクレピング」処理を実装していけば良い、というワケだ。</p>
<p>以降、もう少し詳しく説明していこう。</p>
<h2 id="item-を定義する"><a class="header-link" href="#item-を定義する"><span class="header-link-mark"></span></a>Item を定義する</h2>
<p>スクレイピングしたデータは、最終的に CSV や JSON の形式で出力できる。こうした構造化データを表現するために、Scrapy では <em>Item</em> と呼ばれるクラスを作成しておくことになる。</p>
<p><code>items.py</code> というファイルがあるので、コレを開き、次のように実装しておこう。</p>
<ul>
  <li><code>./my_scrapy/items.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Field<span class="token punctuation">,</span> Item

<span class="token comment"># Item を定義する</span>
<span class="token keyword">class</span> <span class="token class-name">MyExampleItem</span><span class="token punctuation">(</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># 適当にフィールドを定義する</span>
  page_url      <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  page_title    <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  page_headline <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>任意のクラス名で <code>MyExampleItem</code> を作った。<code>class</code> のカッコ部分で <code>Item</code> を渡していて、コレにより <code>scrapy.Item</code> クラスを継承している。</p>
<p><code>page_url</code> や <code>page_title</code> といったフィールド名は任意。取得したいモノに合わせてフィールドを定義しよう。そこに <code>scrapy.Field()</code> を代入して、Scrapy 用のフィールドを宣言してあげている。</p>
<p>この書き方はお決まりなので、深く考えずこのように実装する。</p>
<p>ページ遷移を伴う場合や、取得するデータの構造が異なる場合は、複数の <code>Item</code> クラスを作成して良い。Spider のクラスでは、この <code>items.py</code> から、使いたい <code>Item</code> クラスを <code>import</code> して使う形になる。</p>
<h2 id="スクレイピング処理を実装する"><a class="header-link" href="#スクレイピング処理を実装する"><span class="header-link-mark"></span></a>スクレイピング処理を実装する</h2>
<p>スクレイプした結果を詰める <code>Item</code> クラスを作成したので、いよいよスクレイピング処理を実装してみよう。今回は上で見せた Spider クラスのとおり、<code>example.com</code> にアクセスして、そのページのデータを抜き取ってみる。</p>
<ul>
  <li><code>./my_scrapy/spiders/my_example.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> scrapy

<span class="token comment"># Item を import しておく</span>
<span class="token keyword">from</span> my_scrapy<span class="token punctuation">.</span>items <span class="token keyword">import</span> MyExampleItem

<span class="token keyword">class</span> <span class="token class-name">MyExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
  name <span class="token operator">=</span> <span class="token string">'my_example'</span>
  allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'example.com'</span><span class="token punctuation">]</span>
  
  <span class="token comment"># クロール対象の URL を指定する</span>
  start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://example.com/'</span><span class="token punctuation">]</span>
  
  <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 結果を詰める Item を作成する</span>
    item <span class="token operator">=</span> MyExampleItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># フィールドごとにデータを抽出して詰める</span>
    item<span class="token punctuation">[</span><span class="token string">'page_title'</span><span class="token punctuation">]</span>    <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'title::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    item<span class="token punctuation">[</span><span class="token string">'page_url'</span><span class="token punctuation">]</span>      <span class="token operator">=</span> response<span class="token punctuation">.</span>url
    item<span class="token punctuation">[</span><span class="token string">'page_headline'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'h1::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># Item を出力する</span>
    <span class="token keyword">yield</span> item
</code></pre>
<p>こんな感じ。</p>
<p>基本は、<code>parse()</code> 関数が自動的に渡してくれる <code>response</code> オブジェクトから、上手くデータを抽出していくだけ。</p>
<ul>
  <li><code>css()</code> 関数で CSS セレクタを指定できる
    <ul>
      <li><code>::text</code> とすると、指定のセレクタで特定した要素のテキスト部分だけ抽出できる</li>
      <li>取得結果は配列になっているので、<code>extract_first()</code> で、セレクタが合致した最初の要素だけを取得している</li>
    </ul>
  </li>
  <li>他に <code>xpath()</code> 関数もあり、XPATH 記法でも指定できる</li>
  <li>取得したデータを出力するには、<code>yield Item</code> とする
    <ul>
      <li><code>return Item</code> としてしまうとそこで関数が終了してしまうので、データを出力する時は <code>yield</code>、ガード句的に関数を中断したい時に <code>return</code>、と覚える</li>
    </ul>
  </li>
</ul>
<p><a href="https://example.com">example.com</a> にアクセスすると分かるが、ページには <code>h1</code> 要素があるので、この要素を特定して、中身のテキストを拾っているのが <code>item['page_headline']</code> の代入部分。</p>
<p>とにかくひたすらページの構造に合わせて、このように取得を繰り返していくだけなので、後は愚直に作業していく…。</p>
<h2 id="作成した-spider-を実行する"><a class="header-link" href="#作成した-spider-を実行する"><span class="header-link-mark"></span></a>作成した Spider を実行する</h2>
<p>Spider が実装できたら、実際に実行してみよう。作成した Scrapy プロジェクトに移動して、次のようにコマンドを実行する。</p>
<pre class="language-bash"><code class="language-bash">$ scrapy crawl my_example
</code></pre>
<p>すると、コンソールにデバッグログなどが出力され、最終的に <code>yield Item</code> で出力させた Item 情報が確認できるかと思う。</p>
<p>分かりにくければ、次のように JSON 形式で結果だけ表示させてみよう。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># JSON 形式でコンソール出力する</span>
$ scrapy crawl my_example -t json -o stdout: --nolog
</code></pre>
<p>結果をファイルに出力することもできる。<code>-o</code> オプションで任意のファイル名を指定すると、その拡張子に応じて JSON や CSV 等の形式で Item を出力してくれる。</p>
<pre class="language-bash"><code class="language-bash"><span class="token comment"># JSON ファイルに書き出す</span>
$ scrapy crawl my_example -o my_result.json
</code></pre>
<p>コレが基本的な使い方となる。</p>
<h2 id="ページ遷移を伴う複数-item-を扱う場合"><a class="header-link" href="#ページ遷移を伴う複数-item-を扱う場合"><span class="header-link-mark"></span></a>ページ遷移を伴う・複数 Item を扱う場合</h2>
<p>次は少し高度で、実用的な例を紹介する。ココまでだと、単一の URL にアクセスして、そのページ内の情報を引っこ抜くだけだった。だが実際は、エントリポイントとなるページから、リンク先のページに遷移して、そのページの情報を取得したかったりする。今回はそんな例を作成してみよう。</p>
<h3 id="題材"><a class="header-link" href="#題材"><span class="header-link-mark"></span></a>題材</h3>
<p>題材は僕のサイト Neo's World にアクセスし、グローバルナビゲーションメニューの項目一つひとつのリンクを踏んで、遷移先のページにある <code>h1</code> 要素のテキストを引っこ抜いてみよう。</p>
<p>トップページにあるグローバルナビゲーションメニューは、次のように実装されていることとする。</p>
<pre class="language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>nav</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>nav<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>ul</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/about/index.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>About<span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>li</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/music/index.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Music<span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>li</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/games/index.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Games<span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>li</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/gallery/index.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Gallery<span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>li</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/etc/index.html<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Etc.<span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>li</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>ul</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&#x3C;/</span>nav</span><span class="token punctuation">></span></span>
</code></pre>
<p>遷移先ページは5ページあるワケだ。</p>
<h3 id="item-を作成する"><a class="header-link" href="#item-を作成する"><span class="header-link-mark"></span></a>Item を作成する</h3>
<p>今回は「トップページの情報」と「遷移先ページの情報」とをまとめて、1つの Item に出力しようと思う。JSON でいうとこんな感じだ。</p>
<pre class="language-json"><code class="language-json"><span class="token punctuation">[</span>
  <span class="token punctuation">{</span>
    <span class="token property">"index_page"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"トップページのタイトル"</span><span class="token punctuation">,</span>
      <span class="token property">"url"</span>  <span class="token operator">:</span> <span class="token string">"トップページの URL"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token property">"child_page"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
      <span class="token property">"title"</span>   <span class="token operator">:</span> <span class="token string">"遷移先ページのタイトル"</span><span class="token punctuation">,</span>
      <span class="token property">"url"</span>     <span class="token operator">:</span> <span class="token string">"遷移先ページの URL"</span><span class="token punctuation">,</span>
      <span class="token property">"headline"</span><span class="token operator">:</span> <span class="token string">"遷移先ページの見出しテキスト"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token comment">// 同じ構成で、あと4つ、合計5行分のデータ</span>
<span class="token punctuation">]</span>
</code></pre>
<p>先程 HTML で見せたナビゲーションメニューは5項目あったので、最終的に JSON 配列で5つの要素が取れれば OK だ。<code>index_page</code> プロパティに含めるデータは、5つとも同じ情報が入ることになる。<code>index_page.child_page.headline</code> というように、子プロパティに遷移先ページのデータを持たせていくことも不可能ではないが、Item の取り回しが面倒臭くなるので今回は避ける。</p>
<p>こうしたデータに相当する Item を実装しておく。</p>
<ul>
  <li><code>./my_scrapy/items.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Field<span class="token punctuation">,</span> Item

<span class="token comment"># トップページと遷移先ページの両データを持つ、出力用の Item</span>
<span class="token keyword">class</span> <span class="token class-name">NeosWorldItem</span><span class="token punctuation">(</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
  index_page <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  child_page <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># トップページのデータを格納する Item</span>
<span class="token keyword">class</span> <span class="token class-name">IndexPageItem</span><span class="token punctuation">(</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
  title <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  url   <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 遷移先ページのデータを格納する Item</span>
<span class="token keyword">class</span> <span class="token class-name">ChildPageItem</span><span class="token punctuation">(</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
  title    <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  url      <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  headline <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>このように、3つの Item クラスを作成する。<code>IndexPageItem</code> と <code>ChildPageItem</code> のインスタンスを、<code>NeosWorldItem</code> の各フィールドに持たせて、<code>yield NeosWorldItem</code> と出力する構成だ。</p>
<h3 id="spider-を作成する"><a class="header-link" href="#spider-を作成する"><span class="header-link-mark"></span></a>Spider を作成する</h3>
<p>新たに Spider を作成する。</p>
<pre class="language-bash"><code class="language-bash">$ scrapy genspider neos_world neo.s21.xrea.com
</code></pre>
<p>生成された Spider ファイルを開いて以下のように実装する。</p>
<ul>
  <li><code>my_scrapy/spiders/neos_world.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> my_scrapy<span class="token punctuation">.</span>items <span class="token keyword">import</span> NeosWorldItem<span class="token punctuation">,</span> IndexPageItem<span class="token punctuation">,</span> ChildPageItem

<span class="token keyword">class</span> <span class="token class-name">NeosWorldSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
  name <span class="token operator">=</span> <span class="token string">'neos_world'</span>
  allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'neo.s21.xrea.com'</span><span class="token punctuation">]</span>
  <span class="token comment"># クロール対象の URL を指定する</span>
  start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://neo.s21.xrea.com/'</span><span class="token punctuation">]</span>
  
  <span class="token comment"># トップページ (start_urls) のスクレイピング処理</span>
  <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># トップページ用 Item を作成する</span>
    index_page_item <span class="token operator">=</span> IndexPageItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    index_page_item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'title::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    index_page_item<span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span>   <span class="token operator">=</span> response<span class="token punctuation">.</span>url
    
    <span class="token comment"># ナビゲーションメニューのリンク要素を取得する</span>
    nav_link_elems <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#nav > ul > li > a'</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 万が一、ナビゲーションメニューが1つも存在しない場合は、異常終了とする</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">not</span> nav_link_elems<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token comment"># 異常時は IndexPageItem だけを格納した結果出力用 Item を出力して終了する</span>
      neos_world_item <span class="token operator">=</span> NeosWorldItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
      neos_world_item<span class="token punctuation">[</span><span class="token string">'index_page_item'</span><span class="token punctuation">]</span> <span class="token operator">=</span> index_page_item
      <span class="token keyword">yield</span> neos_world_item
      <span class="token keyword">return</span>
    
    <span class="token comment"># (リンク要素が正常に見つかれば) リンク要素を1つずつ処理する</span>
    <span class="token keyword">for</span> nav_link_elem <span class="token keyword">in</span> nav_link_elems<span class="token punctuation">:</span>
      <span class="token comment"># 1つのリンクの href 属性値を取得する</span>
      nav_href <span class="token operator">=</span> nav_link_elem<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token comment"># 遷移元 URL と href 属性値をかけあわせて、遷移先 URL のフルパスを構成する</span>
      next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>nav_href<span class="token punctuation">)</span>
      
      <span class="token comment"># 遷移先ページにアクセスし、parse_child() 関数に後続の処理を行わせる</span>
      <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>next_url<span class="token punctuation">,</span> callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse_child<span class="token punctuation">,</span> meta <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">'index_page_item'</span><span class="token punctuation">:</span> index_page_item
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
  
  <span class="token comment"># 遷移先ページのスクレイピング処理</span>
  <span class="token keyword">def</span> <span class="token function">parse_child</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># meta で送信されたトップページ用 Item を引き出しておく</span>
    index_page_item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'index_page_item'</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 遷移先ページ用 Item を作成する</span>
    child_page_item <span class="token operator">=</span> ChildPageItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    child_page_item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span>    <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'title::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    child_page_item<span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span>      <span class="token operator">=</span> response<span class="token punctuation">.</span>url
    child_page_item<span class="token punctuation">[</span><span class="token string">'headline'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'h1::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 結果出力用 Item を作成する</span>
    neos_world_item <span class="token operator">=</span> NeosWorldItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    neos_world_item<span class="token punctuation">[</span><span class="token string">'index_page_item'</span><span class="token punctuation">]</span> <span class="token operator">=</span> index_page_item
    neos_world_item<span class="token punctuation">[</span><span class="token string">'child_page_item'</span><span class="token punctuation">]</span> <span class="token operator">=</span> child_page_item
    <span class="token comment"># Item を出力する</span>
    <span class="token keyword">yield</span> neos_world_item
</code></pre>
<p>少し長くなったがこんな感じ。いくつかポイントがあるので押さえておこう。</p>
<ul>
  <li><code>response.css()</code> や <code>xpath()</code> の結果は配列だ。よって <code>if</code> 文で配列要素の存在チェックをしておき、「思っていたとおりのデータが存在しなかった場合」という処理ができる。コレが <code>if(not nav_link_elems):</code> というコードの部分。
    <ul>
      <li>異常時は、その場で Item を構築し、<code>yield Item</code> したら <code>return</code> を呼んで、<code>parse()</code> 関数を終了している</li>
      <li>ほとんどの場合はこの <code>if</code> 文に合致せず、後続の <code>for</code> 文に繋がる</li>
    </ul>
  </li>
  <li><code>response.urljoin()</code> 関数を使うと、遷移元 URL と引数の相対パスをかけ合わせたフルパスが生成できる</li>
  <li><code>scrapy.Request()</code> 関数で、さらなるクローリングが実行できる
    <ul>
      <li>リクエスト処理は <code>yield</code> で扱う</li>
      <li><code>callback</code> の引数で、スクレイピング処理を行う関数を指定できる (<code>callback = self.parse_child</code>)</li>
      <li><code>meta</code> 引数に、コールバック関数に渡したいデータを指定できる。コレを利用して、<em><code>IndexPageItem</code> を引き回している</em></li>
    </ul>
  </li>
  <li>自作した <code>parse_child()</code> 関数も、デフォルトで実装されている <code>parse()</code> 関数と同様の構成で実装すれば良い</li>
  <li><code>meta</code> 引数で引き回したプロパティは <code>response.meta['index_page_item']</code> のように取得できる</li>
</ul>
<p><code>parse()</code> 以降で呼ぶ <code>yield</code> が分かりづらいかもしれないが、</p>
<ul>
  <li><code>yield Item</code> を呼ぶと、その Item を1行の結果データとして出力する</li>
  <li><code>yield scrapy.Request(next_url, callback, meta)</code> を呼ぶと、引数で指定した <code>callback</code> 関数に処理が移行する (<code>meta</code> データも渡せる)</li>
</ul>
<p>という動きをするので、この2つの動きをベースに、最終的にどんな Item を出力したいか、というところをイメージしながら、コールバック関数を作っていくことになる。</p>
<h2 id="入れ子の-item-を出力しようとしたら"><a class="header-link" href="#入れ子の-item-を出力しようとしたら"><span class="header-link-mark"></span></a>入れ子の Item を出力しようとしたら…</h2>
<p>少し前に <code>index_page.child_page.headline</code> というような入れ子関係を作るのが大変、といったが、コレをやろうとすると、こんな実装になるだろう。</p>
<ul>
  <li><code>./my_scrapy/items.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Field<span class="token punctuation">,</span> Item

<span class="token comment"># トップページと、遷移先ページのデータを格納する Item</span>
<span class="token keyword">class</span> <span class="token class-name">IndexPageItem</span><span class="token punctuation">(</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
  title <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  url   <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  child_pages <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 配列で ChildPageItem を格納していく</span>

<span class="token comment"># 遷移先ページのデータを格納する Item</span>
<span class="token keyword">class</span> <span class="token class-name">ChildPageItem</span><span class="token punctuation">(</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
  title    <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  url      <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  headline <span class="token operator">=</span> Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<ul>
  <li><code>my_scrapy/spiders/neos_world.py</code></li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> my_scrapy<span class="token punctuation">.</span>items <span class="token keyword">import</span> IndexPageItem<span class="token punctuation">,</span> ChildPageItem

<span class="token keyword">class</span> <span class="token class-name">NeosWorldSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
  name <span class="token operator">=</span> <span class="token string">'neos_world'</span>
  allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'neo.s21.xrea.com'</span><span class="token punctuation">]</span>
  start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://neo.s21.xrea.com/'</span><span class="token punctuation">]</span>
  
  <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># トップページ用 Item を作成する (同様の処理なので省略)</span>
    index_page_item <span class="token operator">=</span> IndexPageItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 遷移先ページの ChildPageItem を持たせるプロパティを初期化しておく</span>
    index_page_item<span class="token punctuation">[</span><span class="token string">'child_pages'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 遷移先 URL の配列を作る</span>
    child_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> nav_link_elem <span class="token keyword">in</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#nav > ul > li > a'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      child_url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>nav_link_elem<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      child_urls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>child_url<span class="token punctuation">)</span>
    
    <span class="token comment"># 遷移先 URL を配列から1つ取り出し (配列からは取り出した要素が消える)、スクレイピングを行う</span>
    next_url <span class="token operator">=</span> child_urls<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>next_url<span class="token punctuation">,</span> callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse_child<span class="token punctuation">,</span> meta <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token string">'index_page_item'</span><span class="token punctuation">:</span> index_page_item<span class="token punctuation">,</span>
      <span class="token string">'child_urls'</span>     <span class="token punctuation">:</span> child_urls
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
  
  <span class="token comment"># 遷移先ページのスクレイピング処理</span>
  <span class="token keyword">def</span> <span class="token function">parse_child</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># meta で送信されたトップページ用 Item を引き出しておく</span>
    index_page_item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'index_page_item'</span><span class="token punctuation">]</span>
    <span class="token comment"># 遷移先ページの URL 配列も引き出しておく</span>
    child_urls <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'child_urls'</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 遷移先ページ用 Item を作成する (同様の処理なので省略)</span>
    child_page_item <span class="token operator">=</span> ChildPageItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># スクレイピングしたデータを IndexPageItem に追加する</span>
    index_page_item<span class="token punctuation">[</span><span class="token string">'child_pages'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>child_page_item<span class="token punctuation">)</span>
    
    <span class="token comment"># 遷移先ページの URL 配列が空になっていたら、IndexPageItem を出力して終了する</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> child_urls<span class="token punctuation">:</span>
      <span class="token keyword">yield</span> index_page_item
      <span class="token keyword">return</span>
    
    <span class="token comment"># 遷移先 URL を配列から1つ取り出し (配列からは取り出した要素が消える)、スクレイピングを行う</span>
    next_url <span class="token operator">=</span> child_urls<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>next_url<span class="token punctuation">,</span> callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse_child<span class="token punctuation">,</span> meta <span class="token operator">=</span> <span class="token punctuation">{</span>
      <span class="token string">'index_page_item'</span><span class="token punctuation">:</span> index_page_item<span class="token punctuation">,</span>
      <span class="token string">'child_urls'</span>     <span class="token punctuation">:</span> child_urls
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p>一気に関数の実行順序が複雑になったのが分かるだろうか。</p>
<ul>
  <li>最終的に出力するのは <code>yield index_page_item</code> と記している1箇所のみ</li>
  <li>この <code>index_page_item</code> の <code>child_pages</code> プロパティに、複数の <code>ChildPageItem</code> が配列で格納されている</li>
  <li>このような配列での格納を実現するために、遷移先 URL の配列を <code>meta</code> で引き回し、<code>pop()</code> を使って1つずつ取り出す、という操作を行っている</li>
  <li><code>parse()</code> 関数で呼ぶ <code>yield Request()</code> と、<code>parse_child()</code> 関数で呼ぶ <code>yield Request()</code> とは同じ実装になっていて、<code>parse_child()</code> 関数は自分自身をコールバック関数として呼ぶ作りになっている</li>
</ul>
<p>なかなか理解するのが難しいと思うので、やってみたい方は <code>print</code> デバッグしながら動きを追ってみると良いだろう。</p>
<p><code>child_page</code> よりさらに先のページにも遷移して、3階層の入れ子を作りたい、と考え始めるともっとしんどくなるので、Item の入れ子はしない方が良いだろう。</p>
<ul>
  <li>参考：<a href="https://stackoverflow.com/questions/41634126/multiple-nested-request-with-scrapy/41634739#41634739">Multiple nested request with scrapy - Stack Overflow</a>
    <ul>
      <li>入れ子の Item を実現する方法はコチラを参考にした</li>
    </ul>
  </li>
</ul>
<h2 id="以上"><a class="header-link" href="#以上"><span class="header-link-mark"></span></a>以上</h2>
<p>今回はココまで。<code>pipelines.py</code> を実装すれば、収集した Item を DB 投入するところまで一気に実行できたりとか、Scrapy には他にも色々な機能がたくさんあるので、ぜひ活用していってもらいたい。</p>

      </main>
      <footer id="footer">
        <div id="footer-contents">
          <div id="date-time">
            <dl>
              <dt>Created</dt>
              <dd><time>2020-01-31</time></dd>
              <dt>Last-Modified</dt>
              <dd><time>2020-01-31</time></dd>
            </dl>
          </div>
          <nav id="footer-links">
            <ul>
              <li id="footer-link-about"><a href="/about/index.html" title="About">About</a></li>
              <li id="footer-link-search"><a href="/about/search.html" title="Search">Search</a></li>
              <li id="footer-link-feeds"><a href="/feeds.xml" title="Feeds">Feeds</a></li>
              <li id="footer-link-github"><a href="https://github.com/Neos21/" title="GitHub">GitHub</a></li>
            </ul>
          </nav>
          <nav id="to-top"><a href="#" title="To Top"><span>▲ To Top</span></a></nav>
        </div>
      </footer>
    </div>
  </body>
</html>
