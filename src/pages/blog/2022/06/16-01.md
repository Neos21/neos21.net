---
title        : 文字列が「中国語かどうか」を判定したい
created      : 2022-06-16
last-modified: 2022-06-16
header-date  : true
path:
  - /index.html Neo's World
  - /blog/index.html Blog
  - /blog/2022/index.html 2022年
  - /blog/2022/06/index.html 06月
---

漢字だけの文字列を渡して、「日本語」なのか「中国語」なのかを判別するのって、かなり難しかった…。

文章がとっちらかっているが、WIP なライブラリの話をしているので、ご容赦をば…。

## 目次

## 外国語を判定してみたくなった

特に目的はないのだが、ふと思いついて、_ある文字列が外国語の文章かどうか_を判定できる正規表現を書きたいなーと思った。「コレはロシア語だ」とか「コレはハングルだ」みたいな。

_Unicode の「ブロック」_を見ると、ロシア語に使われる「キリル文字」や、韓国語の「ハングル」、「アラビア文字」などは、ブロックが綺麗に別れているので、この Unicode ブロックの範囲で正規表現が書けそうだと気付いた。

- 参考：[ブロック (Unicode) - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%96%E3%83%AD%E3%83%83%E3%82%AF_(Unicode))

なお、ハングルについては以前「ハングルを特定する正規表現」を見つけていて、コレがこの Unicode ブロックにおける_「Hangul Syllables ハングル音節文字」(U+AC00 ～ U+D7AF)_にほぼ相当することが分かった。

- 過去記事：[YouTube ホームの見たくない動画を消すための術](/blog/2022/01/10-01.html)
  > - [ハングルを判定する正規表現 | You Look Too Cool](https://stabucky.com/wp/archives/5058)
  > - `[가-힣]` コレでハングル文字を含む動画を非表示にしたりしてる
- `가` が U+AC00、`힣` が U+D7A3

以下にデモページとコードを用意してみた。

- デモ：[Detect Languages RegExp](https://neos21.github.io/frontend-sandboxes/detect-languages-regexp/index.html)
- コード：[frontend-sandboxes/index.html at master · Neos21/frontend-sandboxes](https://github.com/Neos21/frontend-sandboxes/blob/master/detect-languages-regexp/index.html)

## ES2018 の Unicode Property Escapes という新機能を知る

さらに調べて行くと、__ES2018 で Unicode Property Escapes という機能が追加されていた__のを知った。JS の `RegExp` で `/\p{Script_Extensions=Hangul}/u` と書くことで「ハングルに合致する正規表現」を簡単に書ける、という仕組みだ。

- 参考：[ES2018で入ったUnicode property escapes in regular expressionsを調べてみた - yutaponのブログ](https://yutapon.hatenablog.com/entry/unicode-property-escapes-in-regexp)
- 参考：[JavaScriptのES2018で追加された正規表現の新機能の検証 - Qiita](https://qiita.com/BlueSilverCat/items/dcea3121c7af83148f29)
- 参考：[Unicode property escapes in regular expressions](https://tc39.es/proposal-regexp-unicode-property-escapes/#table-binary-unicode-properties)

Unicode Property Escapes というのは他のプログラミング言語には既に実装されていて、例えば PHP や Ruby なんかでも、`\p{Han}` と書くことで「漢字」にマッチする正規表現を簡単に書けるようだ。Unicode コードポイントを大量に列挙したりしなくて良いワケである。

- 参考：[anton-bot/contains-chinese: Checks whether a string contains at least one Chinese character.](https://github.com/anton-bot/contains-chinese)

他言語の `\p{Han}` (Han というのは「漢」のこと) 相当の正規表現を Unicode コードポイントで記そうとすると、以下のようになる。

```javascript
const HAN_REGEX = /[\u2E80-\u2E99\u2E9B-\u2EF3\u2F00-\u2FD5\u3005\u3007\u3021-\u3029\u3038-\u303B\u3400-\u4DB5\u4E00-\u9FD5\uF900-\uFA6D\uFA70-\uFAD9]/;
```

コレが、ES2018 以降では

```javascript
const HAN_REGEX = /\p{Script=Hani}/u;  // 2つの正規表現は同じ
const HAN_REGEX = /\p{sc=Han}/u;       // コチラは省略記法
```

と、このように書けるワケである。

## 「中国語」と「日本語」は Unicode ブロックが別れていない

さて、「キリル文字」や「ハングル」なんかは、Unicode ブロックでの範囲指定なり、それを上手くグループ化した Unicode Property Escapes という機能でほぼほぼ判定できそうな様子が分かってきた。日本語に関しても、ひらがなとカタカナについては Unicode Property Escapes が存在する。

しかし、_漢字の中でも「中国語」を判定_してみようと思った時、壁にブチ当たった。

Unicode の界隈でよく __CJK__、「CJK 統合漢字」という言葉を耳にしていた。中国語・日本語・朝鮮語で使われる漢字を_ひとまとめ_にした符号表である。

- 参考：[CJK統合漢字 - Wikipedia](https://ja.wikipedia.org/wiki/CJK%E7%B5%B1%E5%90%88%E6%BC%A2%E5%AD%97)

日本語と中国語をひとまとめに…。確かに、日本語の中で使う漢字の多くは、中国の漢字を流用しているので、「CJK」といっしょくたにまとめられているワケだ。しかしそうなると、漢字に関しては、キリル文字やハングルみたいに「この文字がマッチしたからロシア語・韓国語ね！」という簡単な判定ができないことになる。

つまり、膨大な CJK 統合漢字の中から、

- _「日本語において使用される漢字」_と、
- __「中国語の中でのみ使用され、日本語では使用されない漢字」__

とを何とか区別してやらないと、_「この文章が中国語かどうか」を判定するプログラムは書けない_ということだ。

## Unihan データベースを使って「中国語で使われる漢字」を判定する

さらに調べていくと、次のページを見つけた。

- 参考：[あるUnicodeの文字列が中国語かどうかを判定したい - 機略戦記](https://shinya131-note.hatenablog.jp/entry/2015/07/10/004853)

何やら、__Unihan：Unicode Han Database__ という漢字に関するデータベースがあるらしい。データベースと言いながら実体はテキストファイルなのだが、Unicode コードポイントごと (= 漢字ごと) に「日本語の音読み・訓読み」だとか「北京語・広東語での読み方」だとかを記しているようだ。

- 参考：[Unihan Database Lookup](https://unicode.org/charts/unihan.html)
- 参考：[Index of /Public/UNIDATA](http://www.unicode.org/Public/UNIDATA/)
  - __[Unihan.zip](http://www.unicode.org/Public/UNIDATA/Unihan.zip)__
  - ↑ コレがそのデータベースとなるテキストファイルが格納された Zip

また、この Unihan データベースを使って、繁体字と簡体字を区別するような記事もいくつか見かけた。

- 参考：[繁体字と簡体字と日本語を区別する - Qiita](https://qiita.com/Saqoosha/items/927e9d6e77922ad9f08a)

ココに来て_「中国語」とは何か_、ということになるのだが、中国語を勉強したことがないので、よく分かっていない。

ただ、今回僕が考える目的からすると、前述のとおり

- 日本語で使用する漢字だけを含んだ文字列だったら「それは日本語である」と判定し、
- 日本語で使用しない漢字を含んでいる文字列だったら「それは中国語である」と判定したい

ということにする。

そういうワケで、先程の参考ページを参考に Unihan データベースを使ってみることにした。

## 「中国語を判定するプログラム」を作成中

以下の GitHub リポジトリに、作成したコードを置いている。

- [Neos21/detect-chinese: WIP Detect Chinese : 文字列が「中国語かどうか」を判定する](https://github.com/Neos21/detect-chinese)

Node.js で `require()` してもいいし、HTML から読み込めばブラウザ上でも動作するし、`npm install` すれば `$ detect-chinese` コマンドとして動作するような CLI 環境も簡単に用意してみた。以前の記事で少し紹介し、`@neos21/ccc` でも採用している _UMD 形式_でコードを書いている。

- 過去記事：[JavaScript のモジュール管理の仕組みをおさらいする：TypeScript をトランスパイルして HTML 上で利用するための前段](/blog/2018/08/03-02.html)

Unihan データベースの `Unihan_Readings.txt` というファイルから

- 「日本語の音読み・訓読みを持つ漢字」リストと
- 「北京語・広東語読みを持つ漢字」リスト

を抽出し、Unicode コードポイントを列挙して `RegExp` を定義するところまではできた。まぁ巨大な正規表現になった…。

そしてその後の判定についても、__「日本語の音訓読みを持たず、中国語読みを持つ漢字」__を特定したりして、ある程度は「中国語でのみ使われる漢字を含んだ文章かどうか」を判定できている。

## 判定漏れがある

一部、既知の問題として__「つちよし `𠮷`」の文字が日本語とも中国語ともみなされない文字__として扱われてしまっている。

- 一見すると「`吉` と同じく、日本語の中で使われる漢字」っぽく見えるのだが…
- 原因は、「つちよし `𠮷`」の文字が漢字リストの生成に使った `Unihan_Readings.txt` ファイルに定義されていないため
- 「つちよし `𠮷`」の文字は_「スプーフィング異体」_という異字体の扱いで、別のデータベースファイル `Unihan_Variants.txt` の方で `吉` との対応付けが定義されている

そういうワケで、判定漏れしている漢字もまだまだありそうなことが分かっている。

「つちよし `𠮷`」は「日本語漢字」に含めても良いかも知れないが、異字体は他にも沢山あり、それらについては「日本語漢字」とみなしていいのかどうかなど、もう少し考えないといけないところが多そうだ。

## ご意見・アドバイス等ください

中国語をロクに知らないのに、ワケもなく中国語を判定したくなった程度の人間が作っているので、こんな感じで精度はボチボチ。通常の文章なら大抵は「中国語か日本語か (それ以外か)」を判定できているが、もう少しなんとかしていきたい。中国語の有識者のご意見を聴きたい。

最終的に npm パッケージとして配信して汎用的に使えるようにしたいなーと思っているので、どういう機能をライブラリとして提供できれば良いか、要望やアドバイス等あればいつでもご連絡ください。

- [Neos21/detect-chinese: WIP Detect Chinese : 文字列が「中国語かどうか」を判定する](https://github.com/Neos21/detect-chinese)

↑ ご意見がありましたら、GitHub リポジトリの GitHub Issues に起票していただけますと嬉しいです。

---

興味が続けば今後も改修していきます…。笑

<div class="ad-amazon">
  <div class="ad-amazon-image">
    <a href="https://www.amazon.co.jp/dp/B07NPDQJ6X?tag=neos21-22&amp;linkCode=osi&amp;th=1&amp;psc=1">
      <img src="https://m.media-amazon.com/images/I/41B2DmjG6RL._SL160_.jpg" width="112" height="160">
    </a>
  </div>
  <div class="ad-amazon-info">
    <div class="ad-amazon-title">
      <a href="https://www.amazon.co.jp/dp/B07NPDQJ6X?tag=neos21-22&amp;linkCode=osi&amp;th=1&amp;psc=1">新ゼロからスタート中国語 文法編</a>
    </div>
  </div>
</div>

<div class="ad-rakuten">
  <div class="ad-rakuten-image">
    <a href="https://hb.afl.rakuten.co.jp/hgc/g00q0722.waxyc9ff.g00q0722.waxyd017/?pc=https%3A%2F%2Fitem.rakuten.co.jp%2Fbook%2F13148988%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbook%2Fi%2F17346476%2F">
      <img src="https://thumbnail.image.rakuten.co.jp/@0_mall/book/cabinet/2198/9784863922198.jpg?_ex=128x128">
    </a>
  </div>
  <div class="ad-rakuten-info">
    <div class="ad-rakuten-title">
      <a href="https://hb.afl.rakuten.co.jp/hgc/g00q0722.waxyc9ff.g00q0722.waxyd017/?pc=https%3A%2F%2Fitem.rakuten.co.jp%2Fbook%2F13148988%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbook%2Fi%2F17346476%2F">新ゼロからスタート中国語（文法編） だれにでもわかる文法と発音の基本ルール [ 王丹 ]</a>
    </div>
    <div class="ad-rakuten-shop">
      <a href="https://hb.afl.rakuten.co.jp/hgc/g00q0722.waxyc9ff.g00q0722.waxyd017/?pc=https%3A%2F%2Fwww.rakuten.co.jp%2Fbook%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbook%2F">楽天ブックス</a>
    </div>
    <div class="ad-rakuten-price">価格 : 1320円</div>
  </div>
</div>
