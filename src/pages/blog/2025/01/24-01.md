---
title        : Ollama と Open WebUI を使ってセルフホストの ChatGPT もどきを用意する
created      : 2025-01-24
last-modified: 2025-01-24
header-date  : true
path:
  - /index.html Neo's World
  - /blog/index.html Blog
  - /blog/2025/index.html 2025年
  - /blog/2025/01/index.html 01月
---

Ollama という LLM を動かすためのツールがある。コレを使うと簡単に色々なモデルをインストールできる。

今回は Intel N150 搭載の Ubuntu 機で、CPU モードで軽量な LLM を動かしてみることにする。

まずは Ollama をインストールする。

- 参考 : [Download Ollama on Linux](https://ollama.com/download/linux)

```bash
$ curl -fsSL https://ollama.com/install.sh | sh
```

インストールはコレだけ。`ollama` コマンドが叩けるようになる。続いて、日本語で対話できる軽量な LLM を選択してインストール・起動してみる。

```bash
$ ollama run 7shi/ezo-common-t2-gemma-2:2b-instruct-q8_0
```

なんとコレだけ。ターミナルで対話が出来るようになる。回答は一文字ずつストリーム出力されるので、Intel N150 CPU のみのモードで動いていても、そこそこの速度で回答してもらえている気がする。

- 参考 : [Xユーザーのホーダチ | AI✖️Cloud✖️Dev | 外資×ひとり法人さん: 「ミニPCでLLMが動くのか試してみた。 1~3万円でこれは、かなり実用性レベルに近づいてきていると感じる。 https://t.co/Tw9wcRQNYn」 / X](https://x.com/hokazuya/status/1829451601939169699)
- 参考 : [Xユーザーの七誌さん: 「OllamaでGemma 2 2Bを試したら、次に、それをチューニングして日本語性能を向上させたEZO-Common-T2-2B-gemma-2-itを試してみることをお勧めします。アップロードしておきましたので、コマンド一発で使えます。 ollama run 7shi/ezo-common-t2-gemma-2:2b-instruct-q8_0 https://t.co/lnbL9PDg4k」 / X](https://x.com/7shi/status/1825047985413112131)
- 参考 : [7shi/ezo-common-t2-gemma-2:2b-instruct-q8_0](https://ollama.com/7shi/ezo-common-t2-gemma-2:2b-instruct-q8_0)

さて、次はコレをブラウザベースで表示できるようにする、Open WebUI というモノを使ってみる。コチラは Docker でサクッと起動できる。個人で利用するだけなので認証機能は無効にしてある。

```bash
$ docker run -d -p 3000:8080 -e WEBUI_AUTH=False -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main
```

`http://localhost:3000` にアクセスすると、ChatGPT とよく似た UI が開き、先程 Ollama で起動した `7shi/ezo-common-t2-gemma-2:2b-instruct-q8_0` モデルを使った対話ができるようになっている。

- 参考 : [第825回　ローカルLLMの実行ツールであるOllamaをUbuntuで動かす | gihyo.jp](https://gihyo.jp/admin/serial/01/ubuntu-recipe/0825)
- 参考 : [open-webui/open-webui: User-friendly AI Interface (Supports Ollama, OpenAI API, ...)](https://github.com/open-webui/open-webui)
- 参考 : [⏱️ Quick Start | Open WebUI](https://docs.openwebui.com/getting-started/quick-start/#single-user-mode-disabling-login)

あとはコレを Cloudflare Tunnel などを使って外部公開してしまえば、自分だけのプライベートな ChatGPT もどきの出来上がりである。

正直 Intel N150 CPU だけでの動作だと、ChatGPT のような高速な回答は期待できないが、一生懸命考えて出力している感があって中々可愛らしい。ローカル LLM ならプライバシーにも配慮できるので、NVIDIA GPU 搭載マシンがあればなお快適に利用できそうだ。

<div class="ad-rakuten">
  <div class="ad-rakuten-image">
    <a href="https://hb.afl.rakuten.co.jp/hgc/g00q0722.waxyc9ff.g00q0722.waxyd017/?pc=https%3A%2F%2Fitem.rakuten.co.jp%2Fbook%2F18089019%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbook%2Fi%2F21475785%2F&amp;rafcid=wsc_i_is_1051972513434300252">
      <img src="https://thumbnail.image.rakuten.co.jp/@0_mall/book/cabinet/6728/9784296206728_1_32.jpg?_ex=128x128">
    </a>
  </div>
  <div class="ad-rakuten-info">
    <div class="ad-rakuten-title">
      <a href="https://hb.afl.rakuten.co.jp/hgc/g00q0722.waxyc9ff.g00q0722.waxyd017/?pc=https%3A%2F%2Fitem.rakuten.co.jp%2Fbook%2F18089019%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbook%2Fi%2F21475785%2F&amp;rafcid=wsc_i_is_1051972513434300252">ローカルLLM実践入門 [ 日経ソフトウエア ]</a>
    </div>
    <div class="ad-rakuten-shop">
      <a href="https://hb.afl.rakuten.co.jp/hgc/g00q0722.waxyc9ff.g00q0722.waxyd017/?pc=https%3A%2F%2Fwww.rakuten.co.jp%2Fbook%2F&amp;m=http%3A%2F%2Fm.rakuten.co.jp%2Fbook%2F&amp;rafcid=wsc_i_is_1051972513434300252">楽天ブックス</a>
    </div>
    <div class="ad-rakuten-price">価格 : 2530円</div>
  </div>
</div>

<div class="ad-amazon">
  <div class="ad-amazon-image">
    <a href="https://www.amazon.co.jp/dp/B0DQ6NJP36?tag=neos21-22&amp;linkCode=osi&amp;th=1&amp;psc=1">
      <img src="https://m.media-amazon.com/images/I/51-b2EE9wNL._SL160_.jpg" width="112" height="160">
    </a>
  </div>
  <div class="ad-amazon-info">
    <div class="ad-amazon-title">
      <a href="https://www.amazon.co.jp/dp/B0DQ6NJP36?tag=neos21-22&amp;linkCode=osi&amp;th=1&amp;psc=1">ローカルLLM実践入門</a>
    </div>
  </div>
</div>
